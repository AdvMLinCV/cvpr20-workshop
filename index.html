<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <title>CVPR 2020 Workshop on Adversarial Machine Learning in Computer Vision</title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
    <link href="css/style.css" rel="stylesheet" type="text/css"/>
</head>

<body>

<div class="container">
    <table border="0" align="center">
        <tr>
            <td width="700" align="center" valign="middle"><h3>CVPR 2020 Workshop on</h3>
                <span class="title"><strong>Adversarial Machine Learning in Computer Vision</strong></span></td>
        </tr>
        <tr>
        <td colspan="3" align="center"><h3>Seattle, Washington<br>8:30 AM - 7:00 PM  on June 19, 2020</h3></td>
        </tr>
    </table>
    <!--    <p><img src="figures/main.png" width="1000" align="middle"/></p>-->
</div>

</br>

<div class="container">
    <h2>Overview</h2>
    <div class="overview">
        <p>Although computer vision models have achieved advanced performance on various recognition tasks in recent
            years, they are known to be vulnerable against adversarial examples. The existence of adversarial examples
            reveals that current computer vision models perform differently with the human vision system, and on the other
            hand provides opportunities for understanding and improving these models. </p>

        <p>In this workshop, we will focus on recent research and future directions on adversarial machine learning in
            computer vision. We aim to bring experts from the computer vision, machine learning and security communities
            together to highlight the recent progress in this area, as well as discuss the benefits of integrating
            recent progress in adversarial machine learning into general computer vision tasks. Specifically, we seek to
            study adversarial machine learning not only for enhancing the model robustness against adversarial attacks,
            but also as a guide to diagnose/explain the limitation of current computer vision models as well as
            potential improving strategies. We hope this workshop can shed light on bridging the gap between the human
            vision system and computer vision systems, and chart out cross-community collaborations, including computer
            vision, machine learning and security communities.</p>
    </div>
</div>

</br>

<!--<div class="container">-->
<!--    <h2>Important Dates</h2>-->
<!--    TBA-->
<!--</div>-->

<!--</br>-->

<div class="container">
    <h2>Schedule</h2>
    <div class="schedule">
        <p><strong>8:30 - 8:40 &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp Opening Remark</strong></p>
        <p><strong>8:40 - 9:10 &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp &nbsp Invited Talk 1: Alan Yuille - Defending Against Random Occluder Attacks</strong></p>
        <p><strong>9:10 - 9:40 &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp &nbsp Invited Talk 2: Aleksander Madry -  What Do Our Models Learn?</strong></p>
        <p><strong>9:40 - 10:10&nbsp &nbsp &nbsp  &nbsp &nbsp &nbsp Invited Talk 3: Earlence Fernandes - Physical Attacks on Object Detectors</strong></p>
        <p><strong>10:10 - 10:40 &nbsp &nbsp  &nbsp &nbsp Invited Talk 4: Matthias Bethge - Testing Generalization</strong></p>
        <p><strong>10:40 - 11:10 &nbsp &nbsp  &nbsp &nbsp Panel Discussion I: Alan Yuille, Aleksander Madry, Earlence Fernandes and Matthias Bethge</strong></p>
        <p><strong>11:10 - 13:00 &nbsp &nbsp  &nbsp &nbsp Poster Session I</strong></p>
        <p><strong>13:00 - 14:00 &nbsp &nbsp  &nbsp &nbsp Lunch Break</strong></p>
        <p><strong>14:00 - 14:30 &nbsp &nbsp  &nbsp &nbsp Invited Talk 5: Laurens van der Maaten - Adversarial Robustness: The End of the Early Years</strong></p>
        <p><strong>14:30 - 15:00 &nbsp &nbsp  &nbsp &nbsp Invited Talk 6: Pin-Yu Chen - Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness</strong></p>
        <p><strong>15:00 - 15:30 &nbsp &nbsp  &nbsp &nbsp Invited Talk 7: Cho-Jui Hsieh - Adversarial Robustness of Discrete Machine Learning Models</strong></p>
        <p><strong>15:30 - 16:00 &nbsp &nbsp  &nbsp &nbsp Invited Talk 8: Boqing Gong - Towards Domain Adaptation in the Wild: Long-Tailed Sources and Open Compound Targets</strong></p>
        <p><strong>16:00 - 16:30 &nbsp &nbsp  &nbsp &nbsp Invited Talk 9: Thomas G. Dietterich - Setting Alarm Thresholds for Anomaly Detection</strong></p>
        <p><strong>16:30 - 17:00 &nbsp &nbsp  &nbsp &nbsp Panel Discussion II: Laurens van der Maaten, Pin-Yu Chen, Cho-Jui Hsieh, Boqing Gong and Thomas G. Dietterich</strong></p>
        <p><strong>17:00 - 18:50 &nbsp &nbsp  &nbsp &nbsp Poster Session II</strong></p>
        <p><strong>18:50 - 19:00 &nbsp &nbsp  &nbsp &nbsp Closing Remark</strong></p>
    </div>
</div>


</br>
<div class="container">
<h2>Accepted Papers</h2>
<div class="schedule">
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Agarwal_Noise_Is_Inside_Me_Generating_Adversarial_Perturbations_With_Noise_Derived_CVPRW_2020_paper.pdf"><papertitle>Noise is Inside Me! Generating Adversarial Perturbations with Noise Derived from Natural Filters</papertitle></a>
    <br>Akshay Agarwal (IIIT Delhi); Mayank Vatsa (IIT Jodhpur); Richa Singh (IIIT-Delhi); Nalini Ratha (IBM)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Zhang_Learning_Ordered_Top-k_Adversarial_Attacks_via_Adversarial_Distillation_CVPRW_2020_paper.pdf"><papertitle>Learning Ordered Top-k Adversarial Attacks via Adversarial Distillation</papertitle></a>
    <br>Tianfu Wu (NC State University); Zekun Zhang (NC state university)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/14.pdf"><papertitle>On Certifying Robustness against Backdoor Attacks via Randomized Smoothing</papertitle></a>
    <br>Binghui Wang (Duke University); Xiaoyu Cao (Duke University); Jinyuan Jia (Duke University ); Neil Zhenqiang Gong (Duke University)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Mopuri_Adversarial_Fooling_Beyond_Flipping_the_Label_CVPRW_2020_paper.pdf"><papertitle>Adversarial Fooling Beyond "Flipping the Label"</papertitle></a>
    <br>Konda Reddy Mopuri (School of Informatics, University of Edinburgh); Vaisakh Shaj (University Of Lincoln); Venkatesh Babu RADHAKRISHNAN (Indian Institute of Science)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Gupta_Improving_the_Affordability_of_Robustness_Training_for_DNNs_CVPRW_2020_paper.pdf"><papertitle>Improving the affordability of robustness training for DNNs</papertitle></a>
    <br>Sidharth Gupta (University of Illinois at Urbana-Champaign); Parijat Dube (IBM Research); Ashish Verma (IBM Research)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/20.pdf"><papertitle>Disrupting Deepfakes: Adversarial Attacks Against Conditional Image Translation Networks and Facial Manipulation Systems</papertitle></a>
    <br>Nataniel Ruiz (Boston University); Sarah Bargal (Boston University); Stan Sclaroff (Boston University)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Chen_A_Cyclically-Trained_Adversarial_Network_for_Invariant_Representation_Learning_CVPRW_2020_paper.pdf"><papertitle>A Cyclically-Trained Adversarial Network for Invariant Representation Learning</papertitle></a>
    <br>Jiawei Chen (Boston University ); Janusz Konrad (Boston University); Prakash Ishwar (Boston University)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Saha_Role_of_Spatial_Context_in_Adversarial_Robustness_for_Object_Detection_CVPRW_2020_paper.pdf"><papertitle>Role of Spatial Context in Adversarial Robustness for Object Detection</papertitle></a>
    <br>Aniruddha Saha (UMBC); Akshayvarun Subramanya (UMBC); Koninika Patil (UMBC); Hamed Pirsiavash (UMBC)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Hayes_Extensions_and_Limitations_of_Randomized_Smoothing_for_Robustness_Guarantees_CVPRW_2020_paper.pdf"><papertitle>Extensions and limitations of randomized smoothing for robustness guarantees</papertitle></a>
    <br>Jamie Hayes (University College London)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Truong_Systematic_Evaluation_of_Backdoor_Data_Poisoning_Attacks_on_Image_Classifiers_CVPRW_2020_paper.pdf"><papertitle>Systematic Evaluation of Backdoor Data Poisoning Attacks on Image Classifiers</papertitle></a>
    <br>Loc Truong (Western Washington University); Chace Jones (Western Washington University); Nicole Nichols (PNNL); Andrew August (PNNL); Brian Hutchinson (Western Washington University); Brenda Praggastis (PNNL); Robert Jasper (PNNL); Aaron R Tuor (PNNL)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/31.pdf"><papertitle>Fooling Network Interpretation in Image Classification</papertitle></a>
    <br>Akshayvarun Subramanya (UMBC); Vipin Pillai (UMBC); Hamed Pirsiavash (UMBC)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Rounds_Probing_for_Artifacts_Detecting_Imagenet_Model_Evasions_CVPRW_2020_paper.pdf"><papertitle>Probing for Artifacts: Detecting Imagenet Model Evasions</papertitle></a>
    <br>Jeremiah Rounds (PNNL); Addie Kingsland (PNNL; Michael Henry (PNNL); Kayla Duskin (PNNL)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Jefferson_Robust_Assessment_of_Real-World_Adversarial_Examples_CVPRW_2020_paper.pdf"><papertitle>Robust Assessment of Real-World Adversarial Examples</papertitle></a>
    <br>Carlos M Ortiz Marrero (PNNL); Brett Jefferson (PNNL)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/38.pdf"><papertitle>Towards Achieving Adversarial Robustness by Enforcing Feature Consistency Across Bit Planes</papertitle></a>
    <br>Sravanti Addepalli (Indian Institute of Science); Vivek B S (Indian Institute of Science); Arya Baburaj (Indian Institute of Science); Gaurang Sriramanan (Indian Institute of Science); Venkatesh Babu Radhakrishnan (Indian Institute of Science)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Bouniot_Vulnerability_of_Person_Re-Identification_Models_to_Metric_Adversarial_Attacks_CVPRW_2020_paper.pdf"><papertitle>Vulnerability of Person Re-Identification Models to Metric Adversarial Attacks</papertitle></a>
    <br>Quentin Bouniot (CEA LIST); Angélique Loesch (CEA LIST); Romaric Audigier (CEA LIST)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/45.pdf"><papertitle>Data from Model: Extracting Data from Non-robust and Robust Models</papertitle></a>
    <br>Philipp Benz (KAIST); Chaoning Zhang (KAIST); Tooba Imtiaz (KAIST); In So Kweon (KAIST, Korea)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/46.pdf"><papertitle>Universal Adversarial Perturbations are Not Bugs, They are Features</papertitle></a>
    <br>Philipp Benz (KAIST); Chaoning Zhang (KAIST); Tooba Imtiaz (KAIST); In So Kweon (KAIST, Korea)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/51.pdf"><papertitle>Towards Robust LiDAR-based Perception in Autonomous Driving</papertitle></a>
    <br>Jiachen Sun (University of Michigan); yulong cao (University of Michigan, Ann Arbor ); Qi Alfred Chen (UC Irvine); Zhuoqing Morley Mao (University of Michigan)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/54.pdf"><papertitle>Improved Gradient based Adversarial Attacks for Quantized Networks</papertitle></a>
    <br>Kartik Gupta (Australian National University); Thalaiyasingam Ajanthan (ANU)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Costales_Live_Trojan_Attacks_on_Deep_Neural_Networks_CVPRW_2020_paper.pdf"><papertitle>Live Trojan Attacks on Deep Neural Networks</papertitle></a>
    <br>Robby S Costales (Columbia University); Chengzhi Mao (Columbia University); Raphael Norwitz (Nutanix); Bryan Kim (Stanford University); Junfeng Yang (Columbia University)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/70.pdf"><papertitle>Multiview-Robust 3D Adversarial Examples of Real-world Objects</papertitle></a>
    <br>Philip Yao (University of Michigan); Andrew So (California State Polytechnic University at Pomona); Tingting Chen (California State Polytechnic University at Pomona); Hao Ji (California State Polytechnic University at Pomona)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/74.pdf"><papertitle>Unbiased Auxiliary Classifier GANs with MINE</papertitle></a>
    <br>Ligong Han (Rutgers University); Anastasis Stathopoulos (Rutgers University); Tao Xue (Rutgers University); Dimitris N. Metaxas (Rutgers)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/77.pdf"><papertitle>Crafting Adversarial Examples on 3D Object Detection Sensor Fusion Models</papertitle></a>
    <br>Won Park (University of Michigan); Qi Alfred Chen (UC Irvine); Zhuoqing Morley Mao (University of Michigan)</p>
    <p><a href="https://github.com/adv-workshop-2020/adv-workshop-2020.github.io/blob/master/short_papers/79.pdf"><papertitle>Transferable Adversarial Attacks on Deep Reinforcement Learning</papertitle></a>
    <br>Xinlei Pan (UC Berkeley); Yulong Cao (University of Michigan); Xindi Wu (Carnegie Mellon University ); Eric Zelikman (Stanford University); Chaowei Xiao (University of Michigan; Yanan Sui; Rudrasis Chakraborty (UC Berkeley/ICSI); Ronald Fearing (UC Berkeley)</p>
</div>
</div>

<!--</br>-->
<!--<div class="container">-->
<!--    <h2>Call For Papers</h2>-->
<!--    <div class="call4papers">-->
<!--<!--        <p><font color="red">We recently received many inquiries about the ddl extension for the paper submission, due to the inconvenience brought by the breakout of COVID-19. We understand this hard situation for all researchers, and decide to allow 1 more week for the paper submission. This deadline is firm and will not be extended futher. If you need any other accommodations, please let us know and we will try our best to help.</font></p>-->-->
<!--        <p><strong>Submission deadline</strong>: March 15 (<strong><font color="red">NEW: March 22</font></strong>), 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Notification sent to authors</strong>: April 3, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Camera ready deadline</strong>: April 10, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Notification sent to authors</strong>: April 10, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Camera ready deadline</strong>: April 17, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Submission server</strong>: <a href="https://cmt3.research.microsoft.com/CVPRamlcv2020">https://cmt3.research.microsoft.com/CVPRamlcv2020</a></p>-->
<!--        <p><strong>Submission format</strong>: Submissions need to be <strong>anonymized</strong>, and follow the <a href="http://cvpr2020.thecvf.com/submission/main-conference/author-guidelines">CVPR 2020 Submission Guidelines</a>. The workshop considers two types of submissions: (1) <font color="orange"><strong>Long Paper</strong></font>: the page limitation is eight excluding references, and will be included in the official CVPR proceedings; (2) <font color="orange"><strong>Extended Abstract</strong></font>: the page limitation is four excluding references, and will <strong>NOT</strong> be included in the official CVPR proceedings. Based on the PC’s recommendation, the accepted long paper/extended abstract will be allocated either a contributed talk or a poster presentation.</p>-->
<!--        -->
<!--        <p>We invite submissions on <strong>any aspect of adversarial machine learning in computer vision</strong>. This includes, but is not limited to:</p>-->
<!--        <ul>-->
<!--            <li>Adversarial attacks on computer vision models in the digital/physical world</li>-->
<!--            <li>Improving model robustness against adversarial attacks</li>-->
<!--            <li>Theoretical understanding of adversarial machine learning</li>-->
<!--            <li>Applying adversarial machine learning to diagnosing/explaining computer vision models</li>-->
<!--            <li>Improving representation learning via adversarial machine learning </li>-->
<!--            <li>Applications of adversarial machine learning in computer vision tasks (e.g., generative models, image captioning, image recognition)</li>-->
<!--        </ul>-->
<!--        -->
<!--        <p><font color="red">We are excited to announce a <strong>DeepMind Best Paper Award and travel grants</strong>. The workshop is fully sponsored by DeepMind through the University of Oxford.</font></p>-->
<!--        <ul>-->
<!--            <li>The best paper award will be selected from long papers only. The winner will receive the <strong>US$ 1,500 prize and a certificate</strong> at the workshop’s closing.</li>-->
<!--            <li>The workshop has several travel grants (US$100 ~ $200 each) for authors. The travel grants will be considered especially for those from underrepresented groups, such as women and minority ethnic groups.</li>-->
<!--        </ul>-->
<!--    </div>-->
<!--</div>-->

</br>

<div class="container">
    <h2>Speakers</h2>
    <div>
        <div class="instructor">
            <a href="http://www.cs.jhu.edu/~ayuille/index.html">
                <div class="instructorphoto"><img src="figures/alanyuille.png"></div>
                <div>Alan Yuille<br>Johns Hopkins University</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://people.csail.mit.edu/madry/">
                <div class="instructorphoto"><img src="figures/aleksandermadry.jpg"></div>
                <div>Aleksander Mądry<br>MIT</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="http://www.earlence.com/">
                <div class="instructorphoto"><img src="figures/earlencefernandes.jpg"></div>
                <div>Earlence Fernandes<br>UW–Madison</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="http://bethgelab.org/people/matthias/">
                <div class="instructorphoto"><img src="figures/matthiasbethge.jpg"></div>
                <div>Matthias Bethge<br>University of Tübingen</div>
            </a>
        </div>
    </div>

    <p></p>
    <div>
        <div class="instructor">
            <a href="https://lvdmaaten.github.io/">
                <div class="instructorphoto"><img src="figures/laurensvandermaaten.png"></div>
                <div>Laurens van der Maaten<br>Facebook AI Research</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://sites.google.com/site/pinyuchenpage">
                <div class="instructorphoto"><img src="figures/pinyuchen.jpg"></div>
                <div>Pin-Yu Chen<br>IBM</div>
            </a>
        </div>
            
        <div class="instructor">
            <a href="http://web.cs.ucla.edu/~chohsieh/">
                <div class="instructorphoto"><img src="figures/chojuihsieh.jpeg"></div>
                <div>Cho-Jui Hsieh<br>UCLA</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://boqinggong.info/">
                <div class="instructorphoto"><img src="figures/boqinggong.png"></div>
                <div>Boqing Gong<br>Google</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="http://web.engr.oregonstate.edu/~tgd/">
                <div class="instructorphoto"><img src="figures/thomasdietterich.jpg"></div>
                <div>Thomas G. Dietterich<br>Oregon State University</div>
            </a>
        </div>
    </div>
</div>

<!--</br>-->
<!---->
<!--<div class="container">-->
<!--    <h2>Schedule</h2>-->
<!--    TBD-->
<!--    <!--    <div class="schedule">-->-->
<!--    <!--        TBD-->-->
<!--    <!--        <p><span class="announce_date">8:40 - 9:00</span>. Opening Remarks</p>-->-->
<!--    <!--        <p><strong>Session 1: Adversarial Attacks against Computer Vision Systems</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--        <p><strong>Session 2: Improving Model Robustness</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--        <p><strong>Session 3: Understanding the Limitation of Computer Vision Models</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--        <p><strong>Session 4: Interpretable and Explainable Representation Learning</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--    </div>-->-->
<!--</div>-->

</br>

<div class="container">
    <h2>Organizing Committee</h2>
    <div>
        <div class="instructor">
            <a href="https://cihangxie.github.io/">
                <div class="instructorphoto"><img src="figures/cihangxie.jpg"></div>
                <div>Cihang Xie<br>Johns Hopkins University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://jungyhuk.github.io/">
                <div class="instructorphoto"><img src="figures/xinyunchen.jpg"></div>
                <div>Xinyun Chen<br>UC Berkeley</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://songbai.site/">
                <div class="instructorphoto"><img src="figures/songbai.png"></div>
                <div>Song Bai<br>University of Oxford</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://aisecure.github.io/">
                <div class="instructorphoto"><img src="figures/boli.jpg"></div>
                <div>Bo Li<br>UIUC</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://kaiminghe.com/">
                <div class="instructorphoto"><img src="figures/kaiminghe.jpg"></div>
                <div>Kaiming He<br>Facebook AI Research</div>
            </a>
        </div>
    </div>

    <p></p>
    <div>
        <div class="instructor">
            <a href="https://profiles.stanford.edu/fei-fei-li">
                <div class="instructorphoto"><img src="figures/feifeili.jpg"></div>
                <div>Fei-Fei Li<br>Stanford University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www.vision.ee.ethz.ch/en/members/detail/1/#">
                <div class="instructorphoto"><img src="figures/lucvangool.jpg"></div>
                <div>Luc Van Gool<br>ETH Zurich</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://www.robots.ox.ac.uk/~phst/">
                <div class="instructorphoto"><img src="figures/philiptorr.jpg"></div>
                <div>Philip H.S. Torr<br>University of Oxford</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/song.html">
                <div class="instructorphoto"><img src="figures/dawnsong.jpg"></div>
                <div>Dawn Song<br>UC Berkeley</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://www.cs.jhu.edu/~ayuille/index.html">
                <div class="instructorphoto"><img src="figures/alanyuille.png"></div>
                <div>Alan Yuille<br>Johns Hopkins University</div>
            </a>
        </div>
    </div>
</div>
</br>

<div class="container">
    <h2>Program Committee</h2>
    <div class="pcs-row pcs">
        <div class="pcs-column">
            <ul>
                <li>Maksym Andriushchenko (EPFL)</li>
                <li>Anurag Arnab (Google)</li>
                <li>Arjun Nitin Bhagoji (Princeton University)</li>
                <li>Wieland Brendel (University of Tübingen)</li>
                <li>Yulong Cao (University of Michigan)</li>
                <li>Hongge Chen (MIT)</li>
                <li>Ambra Demontis (University of Cagliari)</li>
                <li>Yinpeng Dong (Tsinghua University)</li>
                <li>Sven Gowal (DeepMind)</li>
                <li>Chuan Guo (Cornell University)</li>
                <li>Saumya Jetley (INRIA)</li>
                <li>Adam Kortylewski (Johns Hopkins University)</li>
                <li>Alexey Kurakin (Google Brain)</li>
                <li>Yingwei Li (Johns Hopkins University)</li>
                <li>Jingyue Lu (University of Oxford)</li>
                <li>Jan Hendrik Metzen (Bosch Center for Artificial Intelligence)</li>
                <li>Mahyar Najibi (University of Maryland, College Park)</li>
                <li>Tianyu Pang (Tsinghua University)</li>
                <li>Maura Pintor (University of Cagliari)</li>
            </ul>
        </div>
        <div class="pcs-column">
            <ul>
                <li>Hamed Pirsiavash (UMBC)</li>
                <li>Omid Poursaeed (Cornell University)</li>
                <li>Aaditya Prakash (PathAI)</li>
                <li>Chongli Qin (DeepMind)</li>
                <li>Jonas Rauber (University of Tübingen)</li>
                <li>Aniruddha Saha (UMBC)</li>
                <li>Ali Shafahi (University of Maryland, College Park)</li>
                <li>Yash Sharma (University of Tübingen)</li>
                <li>Akshayvarun Subramanya (UMBC)</li>
                <li>Krishna Kumar Singh (UC Davis)</li>
                <li>David Stutz (Max Planck Institute for Informatics)</li>
                <li>Peng Tang (Salesforce Research)</li>
                <li>Jianyu Wang (Waymo)</li>
                <li>Yuxin Wu (Facebook AI Research)</li>
                <li>Chang Xiao (Columbia University)</li>
                <li>Chaowei Xiao (University of Michigan)</li>
                <li>Hongyang Zhang (Toyota Technological Institute at Chicago)</li>
                <li>Huan Zhang (UCLA)</li>
                <li>Dan Xu (University of Oxford)</li>    
            </ul>
        </div>
    </div>
</div>

</br>

<div class="container">
    <h2>Sponsor</h2>
    <div><img width="350" src="figures/DeepMind_RGB_Lockup_LogoHiRes_Blue.png"></div>
</div>

</br>

<div class="containersmall">
    <p>Please contact <a href="mailto:cihangxie306@gmail.com">Cihang Xie</a> or <a href="mailto:xinyun.chen@berkeley.edu">Xinyun Chen</a> if you have questions. The webpage template
        is by the courtesy of <a href="https://interpretablevision.github.io/">ICCV 2019 Tutorial on Interpretable
            Machine Learning for Computer Vision</a>. Thank <a href="http://yingwei.li/">Yingwei Li</a> for making this website.</p>
</div>

<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
